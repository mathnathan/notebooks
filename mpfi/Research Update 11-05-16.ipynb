{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Picture of Feature Learning...\n",
    "\n",
    "### Supervised Learning\n",
    "Features are automatically extracted internally. For supervised ANNs practitioners sometimes try to extract features before passing the data through the algorithm. Regardless, further features are still extracted and operated on internally.\n",
    "\n",
    "<img src=\"http://www.extremetech.com/wp-content/uploads/2015/01/NeuralNet.jpg\">\n",
    "\n",
    "### Unsupervised\n",
    "Unsupervised learning attempts to find patterns in the data. These patterns can be interpreted as features. For ANNs, the features are exactly the network's internal representation of the data\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Konrad_Kording/publication/274728436/figure/fig2/AS:271715934666753@1441793535194/Figure-2-A-A-stacked-autoencoder-is-trained-on-high-dimensional-data-im-i-1.png\">\n",
    "\n",
    "### Reinforcement\n",
    "This field shows the most promise for true general artificial intelligence. I have not come across much literature discussing the role of features in reinforcement learning. Ideally though, the concept remains the same that the network's internal representation of the data are in some sense the features. This common underlying thread of a network's internal representation being the extracted feature led me to the following idea...\n",
    "\n",
    "<img src=\"https://www.cs.utexas.edu/~eladlieb/rl_interaction.png\">\n",
    "\n",
    "\n",
    "The brain adapts to efficiently represent sensory information in a sparse internal code. This has been well understood in the neuroscience community for a while now. The currently accepted mechanism for this functionality is Hebbian-like plasticity. However, true Hebbian plasticity requires the notion of spike timing and ANNs currently do not like transience as it adds a significant degree of complexity to their calculations. Therefore temporal Hebbian plasticity is currently more or less divorced from ANNs. I am currently unaware of any non-spiking ANNs that utilize Hebbian plasticity. I came up with a mechanism which allows us to adapt the weights of an ANN internally using a temporal-hebbian-plasticity-like approach.\n",
    "\n",
    "As expected, the weights adapt to allow sensory information to be represented internally by a sparse subset of the number of neurons used in the network. The final exciting conclusion which I hope to eventually make, is that these sparse internal codes created by hebbian plasticity are the brains internal feature representation of the data! So, I ultimately would like to come up with a way to map the sparse internal codes back to features in the original data...\n",
    "\n",
    "<img src=\"figure_1_agi.png\">\n",
    "<img src=\"figure_2_agi.png\">\n",
    "<img src=\"figure_3_agi.png\">\n",
    "\n",
    "\n",
    "<img src=\"http://thinkbigdata.in/wp-content/uploads/2016/04/Best_Machine_Learning_Algorithms.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
